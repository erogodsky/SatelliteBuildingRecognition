{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53fc2136-54d2-4081-97f2-c95ac6dd58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 00:20:18.935974: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-05 00:20:18.968421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-05 00:20:19.433124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212f60e3-49eb-4d15-a739-6cc2ad1554ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: /home/user/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by bash)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.2/lib64::/home/user/anaconda3/envs/tf/lib/:/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/user/anaconda3/envs/tf/lib/:/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/user/anaconda3/envs/tf/lib/:/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/user/anaconda3/envs/tf/lib/:/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/user/anaconda3/envs/tf/lib/:/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/user/anaconda3/envs/tf/lib/:/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/nvidia/cudnn/lib\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\n",
    "echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb1bc60-fa73-47c1-8dda-37f7d6ed1167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "print(os.getenv('TF_GPU_ALLOCATOR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8636c9-8b28-4d85-a18a-3d45fdb8508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b6593f-2ebe-4027-b5cf-9603a68db5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d4a802-09c9-4956-af92-c53b30577510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_names.txt', 'PNGImages', 'SegmentationClassPNG']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../voc_multi_semantic_seg_dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6548c47f-2f5b-4c0b-acae-ce5e0869cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing images is optional, CNNs are ok with large images\n",
    "SIZE_X = 512 #Resize images (height  = X, width = Y)\n",
    "SIZE_Y = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1bbf4f-3b2d-4d0a-957e-9904e2bdf9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture training image info as a list\n",
    "train_images = []\n",
    "\n",
    "for directory_path in glob.glob(\"../voc_multi_semantic_seg_dataset/PNGImages\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce829ff4-e77c-4df0-8c82-2f3da9b4633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture mask/label info as a list\n",
    "train_masks = [] \n",
    "\n",
    "for directory_path in glob.glob(\"../voc_multi_semantic_seg_dataset/SegmentationClassPNG\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X))\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "        train_masks.append(mask)\n",
    "        #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "911a8ed5-2388-4881-ab17-ca759229dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use customary x_train and y_train variables\n",
    "X_train = train_images\n",
    "y_train = train_masks\n",
    "y_train = np.expand_dims(y_train, axis=3) #May not be necessary.. leftover from previous code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e5630c-5873-454c-b5c0-09befae7ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 00:20:21.236941: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-05-05 00:20:21.237000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2082 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_1 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 512, 512, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 512, 512, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 256, 256, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 256, 256, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 128, 128, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 64, 64, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load VGG16 model wothout classifier/fully connected layers\n",
    "#Load imagenet weights that we are going to use as feature generators\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE_X, SIZE_Y, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe80c1b-a591-4787-b564-af0a2d8fae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 512, 512, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 512, 512, 64)      36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,720\n",
      "Trainable params: 0\n",
      "Non-trainable params: 38,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#After the first 2 convolutional layers the image dimension changes. \n",
    "#So for easy comparison to Y (labels) let us only take first 2 conv layers\n",
    "#and create a new model to extract features\n",
    "#New model with only first 2 conv layers\n",
    "new_model = Model(inputs=VGG_model.input, outputs=VGG_model.get_layer('block1_conv2').output)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18571822-6bbf-4ea4-a8fa-cd3593b4e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 00:20:21.670702: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 2147483648 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 1210777600/4102881280\n",
      "2023-05-05 00:20:21.670726: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                      2183856128\n",
      "InUse:                      2505194600\n",
      "MaxInUse:                   2505194600\n",
      "NumAllocs:                         145\n",
      "MaxAllocSize:               2147483648\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-05-05 00:20:21.670734: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2023-05-05 00:20:21.670737: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 17\n",
      "2023-05-05 00:20:21.670740: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 4\n",
      "2023-05-05 00:20:21.670742: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 2\n",
      "2023-05-05 00:20:21.670744: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 2\n",
      "2023-05-05 00:20:21.670746: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 3\n",
      "2023-05-05 00:20:21.670748: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2023-05-05 00:20:21.670751: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2048, 6\n",
      "2023-05-05 00:20:21.670753: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 6912, 2\n",
      "2023-05-05 00:20:21.670755: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 1\n",
      "2023-05-05 00:20:21.670757: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 1\n",
      "2023-05-05 00:20:21.670759: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 1\n",
      "2023-05-05 00:20:21.670761: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 1\n",
      "2023-05-05 00:20:21.670764: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 2\n",
      "2023-05-05 00:20:21.670766: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4718592, 1\n",
      "2023-05-05 00:20:21.670768: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9437184, 5\n",
      "2023-05-05 00:20:21.670770: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 97517568, 1\n",
      "2023-05-05 00:20:21.670772: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 100663296, 2\n",
      "2023-05-05 00:20:21.670775: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2147483648, 1\n",
      "2023-05-05 00:20:21.670778: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 2583691264\n",
      "2023-05-05 00:20:21.670781: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 2505194600\n",
      "2023-05-05 00:20:21.670784: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 3791650816\n",
      "2023-05-05 00:20:21.670786: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 2505194600\n",
      "2023-05-05 00:20:21.670795: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:568 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n",
      "2023-05-05 00:20:21.670814: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n",
      "\t [[{{node model/block1_conv1/Relu}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/block1_conv1/Relu' defined at (most recent call last):\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_7313/164044491.py\", line 2, in <module>\n      features=new_model.predict(X_train)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'model/block1_conv1/Relu'\nOOM when allocating tensor with shape[32,64,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n\t [[{{node model/block1_conv1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_498]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Now, let us apply feature extractor to our training data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m features\u001B[38;5;241m=\u001B[39m\u001B[43mnew_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nDetected at node 'model/block1_conv1/Relu' defined at (most recent call last):\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_7313/164044491.py\", line 2, in <module>\n      features=new_model.predict(X_train)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/user/anaconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'model/block1_conv1/Relu'\nOOM when allocating tensor with shape[32,64,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0\n\t [[{{node model/block1_conv1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_498]"
     ]
    }
   ],
   "source": [
    "#Now, let us apply feature extractor to our training data\n",
    "features=new_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4b6b0-7e3f-43b8-ab4e-d79cc9d82a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot features to view them\n",
    "square = 8\n",
    "ix=1\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        ax = plt.subplot(square, square, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(features[0,:,:,ix-1], cmap='gray')\n",
    "        ix +=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f324a9-611a-4d3b-8f42-1dca7afa2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reassign 'features' as X to make it easy to follow\n",
    "X=features\n",
    "X = X.reshape(-1, X.shape[3])  #Make it compatible for Random Forest and match Y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab006ba-7fb6-4271-b493-bd67c8e0d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape Y to match X\n",
    "Y = y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e501e-2943-415c-b5b2-6ddc8bd15a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine X and Y into a dataframe to make it easy to drop all rows with Y values 0\n",
    "#In our labels Y values 0 = unlabeled pixels. \n",
    "dataset = pd.DataFrame(X)\n",
    "dataset['Label'] = Y\n",
    "print(dataset['Label'].unique())\n",
    "print(dataset['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf190b3-81ee-4fb1-8e77-17811a9c8848",
   "metadata": {},
   "outputs": [],
   "source": [
    "##If we do not want to include pixels with value 0 \n",
    "##e.g. Sometimes unlabeled pixels may be given a value 0.\n",
    "dataset = dataset[dataset['Label'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37965c8-8ba9-4fbf-b722-83ab8fb3b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefine X and Y for Random Forest\n",
    "X_for_RF = dataset.drop(labels = ['Label'], axis=1)\n",
    "Y_for_RF = dataset['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e4d9d-f8be-490d-bea8-aa53ffc26224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 50, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a25f1-679c-491f-95da-b7afd5996a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on training data\n",
    "model.fit(X_for_RF, Y_for_RF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7231c22-f320-4164-8530-6071da5c9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model for future use\n",
    "filename = 'RF_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd651ba2-e403-450c-8602-9a747d1070fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model.... \n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab9a9e-cee5-4e1c-9f6c-6aca806b00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test on a different image\n",
    "#READ EXTERNAL IMAGE...\n",
    "test_img = cv2.imread('images/test_images/Sandstone_Versa0360.tif', cv2.IMREAD_COLOR)       \n",
    "test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
    "test_img = np.expand_dims(test_img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33fa821-86e9-4f3f-bffd-71b7ad4ea0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_image = np.expand_dims(X_train[8,:,:,:], axis=0)\n",
    "X_test_feature = new_model.predict(test_img)\n",
    "X_test_feature = X_test_feature.reshape(-1, X_test_feature.shape[3])\n",
    "\n",
    "prediction = loaded_model.predict(X_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68149341-8e18-43d6-b940-efff03b6bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View and Save segmented image\n",
    "prediction_image = prediction.reshape(mask.shape)\n",
    "plt.imshow(prediction_image, cmap='gray')\n",
    "plt.imsave('images/test_images/360_segmented.jpg', prediction_image, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
